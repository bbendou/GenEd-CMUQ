{"code": "11-411", "name": "Natural Language Processing", "base_name": "Natural Language Processing", "units": 12.0, "min_units": 12.0, "max_units": 12.0, "short_name": "NATRL LNGUAG PRCSSNG", "is_topic": false, "topic": null, "prereqs": {"text": "15-122 [] at least D", "req_obj": {"id": 7946465, "screen_name": "2cbxu9a6ghms2r5", "original_min_units": null, "min_units": null, "is_shared": false, "is_uni_req": false, "is_concentration": false, "default_concentration": false, "choices": [{"id": 2154, "screen_name": "15-122", "constraints": [{"type": "course", "type_string": "", "data": {"course": {"code": "15-122", "id": 2153, "name": "Principles of Imperative Computation", "units": 12.0}}, "id": 2153, "is_hidden": false}], "course_parent_id": "79464650000000002154"}], "constraints": [{"type": "anyxof", "type_string": "Fulfill all of the following requirements", "data": {"x": 1, "is_and": true}, "id": 11001994, "is_hidden": false}, {"type": "mingrade", "type_string": "Minimum grade of D", "data": {"grade": "D", "only_transfer_status": false, "only_non_transfer_status": false}, "id": 11001995, "is_hidden": false}]}, "raw_pre_req": ""}, "offered_in_campuses": [1, 2], "offerings": [{"campus_id": 2, "semesters": [{"semester": 1, "year": 2019}, {"semester": 2, "year": 2021}, {"semester": 2, "year": 2022}, {"semester": 2, "year": 2023}, {"semester": 2, "year": 2024}], "sub_semesters": []}, {"campus_id": 1, "semesters": [{"semester": 1, "year": 2023}, {"semester": 2, "year": 2024}, {"semester": 1, "year": 2024}, {"semester": 2, "year": 2025}, {"semester": 1, "year": 2025}], "sub_semesters": []}], "co_reqs": [], "anti_reqs": [], "equiv": [], "long_desc": "This course is about a variety of ways to represent human languages like English and Chinese as computational systems, and how to exploit those representations to write programs that do neat stuff with text and speech data, like translation, summarization, extracting information, question answering, natural interfaces to databases, and conversational agents. This field is called Natural Language Processing or Computational Linguistics, and it is extremely multidisciplinary. This course will therefore include some ideas central to Machine Learning and to Linguistics.  Well cover computational treatments of words, sounds, sentences, meanings, and conversations. Well see how probabilities and realworld text data can help. Well see how different levels interact in stateoftheart approaches to applications like translation and information extraction.  From a software engineering perspective, there will be an emphasis on rapid prototyping, a useful skill in many other areas of Computer Science.", "student_sets": [{"id": 896, "name": "undergraduate"}], "offering_tags": [{"name": "intermittent", "type": "INFO"}], "website": null, "instructors": [], "is_repeatable": false, "is_req_repeatable": false, "repeat_limit_attempts": null, "repeat_limit_credits": null, "catalog_levels": [], "skills": [{"name": "Natural Sciences", "slug": "natural-sciences", "id": 20}, {"name": "Interface Engineering", "slug": "interface-engineering", "id": 826}, {"name": "Linguistics", "slug": "linguistics", "id": 1262}, {"name": "Translation", "slug": "translation", "id": 1268}], "attributes": [{"name": "for non-majors", "id": 6, "type": "attribute"}, {"name": "collaboration & teamwork", "id": 21, "type": "attribute"}], "custom_fields": {"goals": "After successfully completing this course, students will have gained the following knowl edge and skills. Basic, terminology, concepts and applications of natural language processing. Major challenges and issues in computational processing of language. An understanding of the various representational structures used in the processing of natural language, How statistical models are used in modeling aspects of language and how they are implemented and used in processing language. Machine learning techniques used in all aspects of natural language processing and hpw to implement machine learning approaches for natural language processing tasks. How recent teachniques and approaches such as embeddings, encoderdecoder models, and transformerbased systems work. The conceptual and technical basis of large language models. Building nontrivial prototype natural language processing systems.", "key_topics": "Course Overview \u00bf Introduction to NLP 2. Course Project Overview\n3. Naive Bayes and Document Classification 4. Logistic Regression - Inference\n5. Logistic Regression - Training\n6. Feed-Forward Neural Networks and Backpropagation 7. Neural Language Models\n8. Vector Semantics and Embeddings\n9. Sequence Labeling, RNNs\n10. Encoder/Decoder Architectures, Self-Attention and Transformers 11. Transformer Language Models: BERT, finetuning\n12. NN Toolkits\n13. Text-in-text-out and prompting; GPT, GPT2, GPT-3, LLaMa 2 14. Reinforcement Learning with Human Feedback and ChatGPT 15. Reference and Co-reference resolution\n16. Machine Translation\n17. Natural-Language Inference and Reasoning over Texts 18. Chatbots and Task-oriented Chatbots\n19. QA and Multilingual QA\n20. Humor Detection/Toxic Speech Detection\n21. Fact Checking / Fake News Detection 22. Speech Recognition and Synthesis\n23. Multi-lingual NLP.", "prerequisite_knowledge": "Strong programming skills (in Python)\nA course in data structures and algorithms (or equivalent experience)\nA basic knowledge of probability theory and linear algebra", "assessment_structure": "Exams, Quizzes, Homeworks", "relevance": "CS Constrained Elective", "learning_resources": "Online book", "extra_time_commitment": null}, "admin_context": {"suggested_by_advisor": null, "counts_for": []}, "success": true}